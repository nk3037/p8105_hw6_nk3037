---
title: "P8105_hw6_nk3037"
author: "Navya Koneripalli"
date: "2023-11-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(viridis)
library(broom)
library(modelr)
library(purrr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Question 2
### Setup
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

In this model, 'tmax' is the response and 'tmin' and 'prcp' are the predictors. 
```{r}
# Initial linear model
lin_model = lm(tmax ~ tmin + prcp, data = weather_df)
```

Plotting r-square distribution using 5000 bootstrap samples
```{r}
# Bootstrapping
weather_rsq = weather_df %>% 
    modelr::bootstrap(n = 5000, id="strap_count") %>%  
    mutate(
     models = map(.x=strap, ~lm(tmax ~ tmin + prcp, data = .x)),
     results = map(.x=models, broom::glance)) %>% 
    select(strap_count, results) %>% 
    unnest(results) 

# Plotting
weather_rsq %>% 
  ggplot(aes(x = r.squared)) + geom_density()

# Calculating CIs
weather_rsq %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975))
```

The distribution of r squared is skewed left. The most common r^2 value is between 0.92-0.925. The mean r^2 value is 0.92. Since the distribution is not normal, it may be safe to assume that a linear model is not the best approach for this data and instead a generalized linear model or non-parametric methods may be better.

Plotting log(b1*b2) distribution using 5000 bootstrap samples
```{r}
# Bootstrapping
weather_logb = weather_df %>% 
    modelr::bootstrap(n = 5000, id="strap_number") %>% 
     mutate(
      models = map(.x=strap, ~lm(tmax ~ tmin + prcp, data = .x)),
      results = map(models, broom::tidy)) %>% 
    select(strap_number, results) %>% 
    unnest(results) %>% 
    pivot_wider(
      names_from = term, 
      values_from = estimate) %>% 
    group_by(strap_number) %>% 
    summarize(
     tmin = first(na.omit(tmin)),
     prcp = first(na.omit(prcp)),
     log_product = log(tmin * prcp)
    )

# Plotting
weather_logb %>% 
  filter(log_product!="NaN") %>% 
  ggplot(aes(x=log_product))+geom_density()

# Calculating CIs
log_product_conf_int =weather_logb |> 
  summarize(
    lower_ci = quantile(log_product, 0.025, na.rm=TRUE),
    upper_ci = quantile(log_product, 0.975,na.rm=TRUE)
  )
```

The distribution of the log product is left-skewed with the curve peaking at around -5.5 on a graph of range -13 to -4. The 95% confidence interval is (-8.947,-4.571). 

## Question 3
```{r}
# Loading the birth weight data
birthweight = read_csv("./data/birthweight.csv")

# Data cleaning
birthweight = janitor::clean_names(birthweight, case = "snake")%>% 
  mutate(
    babysex = factor(babysex),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9)),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8)),
    malform = factor(malform),
    smoken = factor(smoken),
    parity = factor(parity)
  ) %>% 
  na.omit(birthweight)

# Regression model
model1 = lm (bwt ~ mheight + delwt, data = birthweight)
summary(model1)
```

The simple linear model examines the effect that mother's height and weight have on birth weight. I think the mother's weight and height are the most accurate predictors for the baby's weight. I think these variables are stronger predictors than income or race/ethnicity, and than the biological determinants of health have a greater impact on birth weight than the environmental and social determinants.

### Model residuals vs fitted values
```{r}
birthweight %>% 
  add_predictions(model1)  %>% 
  add_residuals(model1)  %>% 
  ggplot(aes(x = pred, y = resid)) +  geom_point() +
  geom_smooth(method = "lm") +
  labs(
    title = "Residuals vs Fitted Values ")
```

Based on the fitted values vs predicted values plot, since the points are clustered symmetrically around 0, we can conclude that the variability of the residuals varies across different levels of the fitted values. This indicates heteroscedasticity. This means the relationship between predictors and the response variable is not linear.
 
### Comparing to the other two models
```{r}
model2 = lm(bwt ~ blength + gaweeks, data = birthweight)
model3 = lm(bwt ~ bhead * blength * babysex, data = birthweight)

cv_df =
  crossv_mc(birthweight, 100)  # 100 cross validation runs

cv_df = 
  cv_df %>% 
  mutate(
    model1  = map(.x = train, ~lm(bwt~mheight + delwt, data = .x)),
    model2  = map(.x = train, ~lm(bwt~blength+gaweeks, data = .x)),
    model3  = map(.x = train, ~lm(bwt~bhead*blength + bhead*babysex + blength*babysex, data = .x)))  %>%
  mutate(
    rmse_model1= map2_dbl(.x=model1, .y=test, ~rmse(model = .x, data = .y)),
    rmse_model2= map2_dbl(.x=model2, .y=test, ~rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(.x=model3, .y=test, ~rmse(model = .x, data = .y)) 
  ) 

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(
    model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

Based on the violin plot, model 3 has the lowest RMSE. Models 2 and 3, which both have significantly greater RMSE than model 1 and that is why I would choose model 3 as it explains more of the variability in 'bwt' based on R-squared values and has a lower RMSE than model 2. 